name: "jobs"
description: "Trigger an one-time job run on Databricks"


inputs:
  databricks_host:
    required: true
    description: "The URL of your Databricks workspace, e.g. https://westeurope.azuredatabricks.net"
  databricks_token:
    required: true
    description: "The Databricks token to use for authentication"
  databricks_path:
    required: true
    description: "The path in Databricks where the repository should be imported"
  folder_path:
    required: true
    description: "The path to the folder containing the notebook to run"
  requirements_path:
    required: true
    description: "The path to the requirements.txt file"
  cluster_config_path:
    required: true
    description: "The path to the json file for the cluster configuration"


runs:
  using: "composite"
  steps:
    - name: Import libraries
      shell: bash
      run: |
        pip install requests

    - name: Get environment
      id: check
      shell: bash
      run: |
        python3 -c '
        import requests
        import json
        import os
        import time


        class DatabricksJobs:
            def __init__(self, databricks_url: str, databricks_token: str):
                self.databricks_url = databricks_url
                self.databricks_token = databricks_token

            @staticmethod
            def get_all_files_in_folder(folder_path) -> list[str]:
                """Get all the files in a folder whether in subdir or not."""
                all_files = []
                for foldername, _, filenames in os.walk(folder_path):
                    for filename in filenames:
                        if filename.endswith(".py"):
                            file_path = os.path.join(foldername, filename)
                            fixed_path = file_path.replace("\\", "/").replace(".py", "")
                            all_files.append(fixed_path)
                return all_files

            @staticmethod
            def get_requirements(requirements_path: str) -> list[dict]:
                """Get the requirements from the requirements.txt file."""
                requirements = []
                with open(requirements_path, "r") as f:
                    for line in f.readlines():
                        requirements.append(
                            {"pypi":{"package": line.replace("\n", "")}}
                        )
                return requirements

            @staticmethod
            def get_cluster_config(cluster_config_path: str) -> dict:
                return json.load(open(cluster_config_path))

            def create_tasks(
                self,
                databricks_path: str,
                folder_path: str,
                requirements_path: str,
                cluster_config_path: str,
            ) -> list[dict]:
                """Create a list of tasks to be submitted to Databricks."""
                all_files = self.get_all_files_in_folder(folder_path)
                requirements = self.get_requirements(requirements_path)
                cluster_config = self.get_cluster_config(cluster_config_path)
                tasks = []
                for file in all_files:
                    len_folder_path = len(folder_path)
                    fixed_file = file[len_folder_path + 1:]
                    tasks.append({
                        "task_key": fixed_file,
                        "new_cluster": cluster_config,
                        "libraries": requirements,
                        "notebook_task": {
                            "notebook_path": f"{databricks_path}/{file}",
                            "source": "WORKSPACE",
                        }
                    })
                return tasks

            def one_time_run(
                self,
                job_name: str,
                tasks: list[dict],
            ) -> int:
                """Submit a one-time run to Databricks."""
                response = requests.post(
                    f"{self.databricks_url}/api/2.1/jobs/runs/submit",
                    headers={"Authorization": f"Bearer {self.databricks_token}"},
                    json={
                        "run_name": job_name,
                        "tasks": tasks,
        }
                )
                if response.status_code >= 300:
                    print(response.json())
                    raise Exception(f"Job failed to be submitted.")
                return response.json()["run_id"]

            def await_run_completion(self, run_id: int) -> None:
                # Get the status of the job from the api
                response = requests.get(
                    f"{self.databricks_url}/api/2.1/jobs/runs/get?run_id={run_id}",
                    headers={"Authorization": f"Bearer {self.databricks_token}"}
                )

                # If the status code is not 200, raise an exception
                if response.status_code >= 300:
                    raise Exception(f"Job failed to be retrieved.")
                # If the status code is 200, check if the job is still running
                else:
                    # Print job link
                    job_id = response.json()["job_id"]
                    link = f"{self.databricks_url}/#job/{job_id}/run/{run_id}"
                    message = (
                        "Job is running. Click on the link below: \n"
                        f"{link} \n"
                    )
                    print(message)

                    status = response.json()["state"].get("result_state")
                    while not status:
                        print("Job is still running...")
                        response = requests.get(
                            f"{self.databricks_url}/api/2.1/jobs/runs/get?run_id={run_id}",
                            headers={"Authorization": f"Bearer {self.databricks_token}"}
                        )
                        status = response.json()["state"].get("result_state")
                        time.sleep(30)
                    # If the job is not running, check if it was successful
                    if response.json()["state"]["result_state"] == "SUCCESS":
                        print("Job completed successfully.")
                    # If the job is not running and it failed, raise an exception
                    else:
                        message = (
                            "Job failed. Click on the link below: \n"
                            f"{link} \n"
                        )
                        print(message)
                        raise Exception(message)


        job = DatabricksJobs(
            databricks_url="${{ inputs.databricks_host }}",
            databricks_token="${{ inputs.databricks_token }}"
        )
        tasks = job.create_tasks(
            databricks_path="${{ inputs.databricks_path }}",
            folder_path="${{ inputs.folder_path }}", 
            requirements_path="${{ inputs.requirements_path }}",
            cluster_config_path="${{ inputs.cluster_config_path }}",
        )
        run_id = job.one_time_run(
            job_name="${{ inputs.databricks_path }}".split("/")[-1],
            tasks=tasks,
        )
        job.await_run_completion(run_id=run_id)
        '